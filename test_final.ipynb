{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingModel(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, estimators):\n",
    "        super().__init__()\n",
    "        self.estimators = estimators\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_preds = [estimator.predict(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        y_preds = [estimator.predict_proba(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre processing\n",
    "def drop_high_null_columns(df, threshold=0.5):\n",
    "    null_percentages = df.select([(pl.col(col).is_null().mean()).alias(col) for col in df.columns])\n",
    "    cols_to_drop = [\n",
    "        col\n",
    "        for col in null_percentages.columns\n",
    "        if null_percentages.select(pl.col(col)).item() > threshold\n",
    "    ]\n",
    "    df = df.drop(cols_to_drop)\n",
    "    return df\n",
    "\n",
    "# def impute_missing_values(df):\n",
    "#     # Iterate over each column\n",
    "#     for col in df.columns:\n",
    "#         # Check if the column has null values\n",
    "#         if df[col].null_count() > 0:\n",
    "#             # If the column is numerical, fill null values with the mean\n",
    "#             if df[col].dtype == pl.Float64:\n",
    "#                 mean_value = df[col].mean()\n",
    "#                 df[col] = df[col].fill_null(mean_value)\n",
    "#             # If the column is categorical, fill null values with the mode\n",
    "#             elif df[col].dtype == pl.Utf8:\n",
    "#                 mode_value = df[col].mode()[0]\n",
    "#                 df[col] = df[col].fill_null(mode_value)\n",
    "#     return df\n",
    "\n",
    "# def impute_missing_values(df):\n",
    "#     # Iterate over each column\n",
    "#     for col in df.columns:\n",
    "#         # Check if the column has null values\n",
    "#         if df[col].null_count() > 0:\n",
    "#             # If the column is numerical, fill null values with the mean\n",
    "#             if df[col].dtype == pl.Float64:\n",
    "#                 mean_value = df[col].mean()\n",
    "#                 df = df.with_column(col, df[col].fill_null(mean_value))\n",
    "#             # If the column is categorical, fill null values with the mode\n",
    "#             elif df[col].dtype == pl.Utf8:\n",
    "#                 mode_value = df[col].mode()[0]\n",
    "#                 df = df.with_column(col, df[col].fill_null(mode_value))\n",
    "#     return df\n",
    "\n",
    "# def drop_low_high_cardinality_columns(df, low_threshold=1, high_threshold=1000):\n",
    "#     unique_counts = df.select([pl.col(col).n_unique().alias(col) for col in df.columns if df[col].dtype == pl.Utf8])\n",
    "#     cols_to_drop = []\n",
    "#     for col in unique_counts.columns:\n",
    "#         unique_count = unique_counts.select(pl.col(col)).item()\n",
    "#         if unique_count == low_threshold or unique_count > high_threshold:\n",
    "#             cols_to_drop.append(col)\n",
    "    \n",
    "#     df = df.drop(cols_to_drop)\n",
    "#     return df\n",
    "\n",
    "# def impute_missing_values(df):\n",
    "#     # Iterate over each column\n",
    "#     for col in df.columns:\n",
    "#         # Check if the column has null values\n",
    "#         if df[col].null_count() > 0:\n",
    "#             # If the column is numerical, fill null values with the mean\n",
    "#             if df[col].dtype == pl.Float64:\n",
    "#                 mean_value = df[col].mean()\n",
    "#                 df = df.with_columns([(col, df[col].fill_null(mean_value))])\n",
    "#             # If the column is categorical, fill null values with the mode\n",
    "#             elif df[col].dtype == pl.Utf8:\n",
    "#                 mode_value = df[col].mode()[0]\n",
    "#                 df = df.with_columns([(col, df[col].fill_null(mode_value))])\n",
    "#     return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    @staticmethod\n",
    "    def set_table_dtypes(df):\n",
    "        for col in df.columns:\n",
    "            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Int32))\n",
    "            elif col in [\"date_decision\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "            elif col[-1] in (\"P\", \"A\"):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
    "            elif col[-1] in (\"M\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.String))\n",
    "            elif col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))            \n",
    "\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def handle_dates(df):\n",
    "        for col in df.columns:\n",
    "            if col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n",
    "                df = df.with_columns(pl.col(col).dt.total_days())\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float32))\n",
    "                \n",
    "        df = df.drop(\"date_decision\", \"MONTH\")\n",
    "\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def filter_cols(df):\n",
    "        # List of attributes to exclude\n",
    "\n",
    "        # manual select the columns to remove\n",
    "        excluded_attributes = [\n",
    "            \"addres_district_368M\", \"addres_role_871L\", \"addres_zip_823M\",\n",
    "            \"amtinstpaidbefduel24m_4187115A\", \"annualeffectiverate_199L\", \"annuity_853A\",\n",
    "            \"applicationcnt_361L\", \"applications30d_658L\", \"applicationscnt_1086L\",\n",
    "            \"applicationscnt_464L\", \"applicationscnt_629L\", \"applicationscnt_867L\",\n",
    "            \"approvaldate_319D\", \"assignmentdate_238D\", \"assignmentdate_4527235D\",\n",
    "            \"assignmentdate_4955616D\", \"bankacctype_710L\", \"birth_259D\", \"birthdate_574D\",\n",
    "            \"birthdate_87D\", \"byoccupationinc_3656910L\", \"cardtype_51L\", \"childnum_21L\",\n",
    "            \"classificationofcontr_1114M\", \"classificationofcontr_13M\", \"classificationofcontr_400M\",\n",
    "            \"clientscnt_100L\", \"clientscnt_1022L\", \"clientscnt_1071L\", \"clientscnt_1130L\",\n",
    "            \"clientscnt_136L\", \"clientscnt_157L\", \"clientscnt_257L\", \"clientscnt_304L\",\n",
    "            \"clientscnt_360L\", \"clientscnt_493L\", \"clientscnt_533L\", \"clientscnt_887L\",\n",
    "            \"clientscnt_946L\", \"clientscnt12m_3712952L\", \"clientscnt3m_3712950L\",\n",
    "            \"clientscnt6m_3712949L\", \"cntpmts24_3658933L\", \"collater_typofvalofguarant_298M\",\n",
    "            \"collater_typofvalofguarant_407M\", \"collaterals_typeofguarante_359M\",\n",
    "            \"collaterals_typeofguarante_669M\", \"contaddr_district_15M\", \"contaddr_matchlist_1032L\",\n",
    "            \"contaddr_smempladdr_334L\", \"contaddr_zipcode_807M\", \"contractdate_551D\",\n",
    "            \"contractenddate_991D\", \"contractmaturitydate_151D\", \"contractst_964M\",\n",
    "            \"contractsum_5085717L\", \"contracttype_653M\", \"conts_role_79M\", \"conts_type_509L\",\n",
    "            \"creationdate_885D\", \"credlmt_228A\", \"credlmt_230A\", \"credor_3940957M\", \"credtype_322L\",\n",
    "            \"credtype_587L\", \"dateactivated_425D\", \"datefirstoffer_1144D\", \"datelastinstal40dpd_247D\",\n",
    "            \"datelastunpaid_3546854D\", \"dateofcredend_289D\", \"dateofcredend_353D\", \"dateofcredstart_181D\",\n",
    "            \"dateofcredstart_739D\", \"dateofrealrepmt_138D\", \"deductiondate_4917603D\", \"description_351M\",\n",
    "            \"description_5085714M\", \"disbursementtype_67L\", \"district_544M\", \"dpdmaxdatemonth_804T\",\n",
    "            \"dpdmaxdatemonth_89T\", \"dpdmaxdateyear_596T\", \"dpdmaxdateyear_742T\", \"dpdmaxdateyear_896T\",\n",
    "            \"dtlastpmt_581D\", \"dtlastpmtallstes_3545839D\", \"dtlastpmtallstes_4499206D\", \"education_1103M\",\n",
    "            \"education_1138M\", \"education_88M\", \"education_927M\", \"eir_270L\", \"empl_employedfrom_271D\",\n",
    "            \"empladdr_district_926M\", \"empladdr_zipcode_114M\", \"employedfrom_700D\", \"employername_160M\",\n",
    "            \"empls_employedfrom_796D\", \"empls_employer_name_740M\", \"familystate_447L\", \"familystate_726L\",\n",
    "            \"financialinstitution_382M\", \"financialinstitution_591M\", \"firstclxcampaign_1125D\",\n",
    "            \"firstdatedue_489D\", \"firstnonzeroinstldate_307D\", \"fourthquarter_440L\", \"gender_992L\",\n",
    "            \"housetype_905L\", \"housingtype_772L\", \"incometype_1044T\", \"inittransactioncode_186L\",\n",
    "            \"inittransactioncode_279L\", \"isbidproduct_1095L\", \"isbidproduct_390L\", \"isbidproductrequest_292L\",\n",
    "            \"isdebitcard_527L\", \"isdebitcard_729L\", \"language1_981M\", \"last180dayturnover_1134A\",\n",
    "            \"last30dayturnover_651A\", \"lastactivateddate_801D\", \"lastapplicationdate_877D\",\n",
    "            \"lastapprcommoditycat_1041M\", \"lastapprcommoditytypec_5251766M\", \"lastapprdate_640D\",\n",
    "            \"lastcancelreason_561M\", \"lastdelinqdate_224D\", \"lastrejectcommoditycat_161M\",\n",
    "            \"lastrejectcommodtypec_5251769M\", \"lastrejectdate_50D\", \"lastrejectreason_759M\",\n",
    "            \"lastrejectreasonclient_4145040M\", \"lastrepayingdate_696D\", \"lastupdate_1112D\",\n",
    "            \"lastupdate_260D\", \"lastupdate_388D\", \"maritalst_385M\", \"maritalst_703L\", \"maritalst_893M\",\n",
    "            \"maxdpdinstldate_3546855D\", \"mobilephncnt_593L\", \"name_4527232M\", \"name_4917606M\",\n",
    "            \"numberofoverdueinstlmaxdat_148D\", \"numberofoverdueinstlmaxdat_641D\", \"openingdate_313D\",\n",
    "            \"openingdate_857D\", \"overdueamountmax2date_1002D\", \"overdueamountmax2date_1142D\",\n",
    "            \"overdueamountmaxdatemonth_284T\", \"overdueamountmaxdatemonth_365T\", \"overdueamountmaxdatemonth_494T\",\n",
    "            \"overdueamountmaxdateyear_2T\", \"overdueamountmaxdateyear_432T\", \"overdueamountmaxdateyear_994T\",\n",
    "            \"paytype_783L\", \"paytype1st_925L\", \"payvacationpostpone_4187118D\", \"periodicityofpmts_1102L\",\n",
    "            \"periodicityofpmts_837L\", \"personindex_1023L\", \"persontype_1072L\", \"persontype_792L\",\n",
    "            \"posfpd10lastmonth_333P\", \"posfpd30lastmonth_3976960P\", \"posfstqpd30lastmonth_3976962P\",\n",
    "            \"postype_4733339M\", \"previouscontdistrict_112M\", \"processingdate_168D\", \"purposeofcred_426M\",\n",
    "            \"purposeofcred_722M\", \"purposeofcred_874M\", \"registaddr_district_1083M\", \"registaddr_zipcode_184M\",\n",
    "            \"rejectreason_755M\", \"rejectreasonclient_4145042M\", \"relatedpersons_role_762T\",\n",
    "            \"relationshiptoclient_415T\", \"relationshiptoclient_642T\", \"requesttype_4525192L\",\n",
    "            \"responsedate_1012D\", \"responsedate_4527233D\", \"responsedate_4917613D\", \"role_1084L\",\n",
    "            \"role_993L\", \"secondquarter_766L\", \"sellerplacecnt_915L\", \"sellerplacescnt_216L\",\n",
    "            \"sex_738L\", \"subjectrole_182M\", \"subjectrole_326M\", \"subjectrole_43M\", \"subjectrole_93M\",\n",
    "            \"thirdquarter_1082L\", \"twobodfilling_608L\", \"type_25L\", \"typesuite_864L\", \"validfrom_1069D\"\n",
    "        ]\n",
    "\n",
    "\n",
    "        # Exclude the attributes\n",
    "        df = df.drop(excluded_attributes, errors='ignore')\n",
    "    \n",
    "           # Print the number of columns left\n",
    "        print(\"Number of columns left after excluding:\", len(df.columns))\n",
    "\n",
    "       # Preprocess the dataframe\n",
    "        df = drop_high_null_columns(df)\n",
    "        # Print the number of columns left\n",
    "        print(\"Number of columns left after droping the null:\", len(df.columns))\n",
    "        #df = drop_low_high_cardinality_columns(df)\n",
    "\n",
    "        # print the number of columns left\n",
    "        #print(\"Number of columns left after droping the low and high cardinality columns:\", len(df.columns))\n",
    "\n",
    "        # Print the columns that have null values\n",
    "        null_columns = [col for col in df.columns if df[col].null_count() > 0]\n",
    "        print(\"Columns with null values:\", null_columns)\n",
    "\n",
    "                # Print the number of columns left\n",
    "        print(\"Number of columns left after dropping the low and high cardinality columns:\", len(df.columns))\n",
    "\n",
    "        # Print the null values for each column\n",
    "        for col in df.columns:\n",
    "            null_count = df[col].null_count()\n",
    "            print(f\"Null values in '{col}': {null_count}\")\n",
    "\n",
    "        # df = impute_missing_values(df)\n",
    "\n",
    "        if df[col].dtype == 'object' or df[col].dtype == 'category':\n",
    "            mode = df[col].mode().iloc[0]\n",
    "            df[col] = df[col].fillna(mode,inplace=True)\n",
    "        else:\n",
    "            mean = df[col].mean()\n",
    "            df[col] = df[col].fillna(mean,inplace=True)\n",
    "\n",
    "         # Print the null values for each column\n",
    "        for col in df.columns:\n",
    "            null_count = df[col].null_count()\n",
    "            print(f\"Null values in '{col}': {null_count}\")\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregator:\n",
    "    @staticmethod\n",
    "    def num_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n",
    "\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "\n",
    "        return expr_max\n",
    "\n",
    "    @staticmethod\n",
    "    def date_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"D\",)]\n",
    "\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "\n",
    "        return expr_max\n",
    "\n",
    "    @staticmethod\n",
    "    def str_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n",
    "        \n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "\n",
    "        return expr_max\n",
    "\n",
    "    @staticmethod\n",
    "    def other_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n",
    "        \n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "\n",
    "        return expr_max\n",
    "    \n",
    "    @staticmethod\n",
    "    def count_expr(df):\n",
    "        cols = [col for col in df.columns if \"num_group\" in col]\n",
    "\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "\n",
    "        return expr_max\n",
    "\n",
    "    @staticmethod\n",
    "    def get_exprs(df):\n",
    "        exprs = Aggregator.num_expr(df) + \\\n",
    "                Aggregator.date_expr(df) + \\\n",
    "                Aggregator.str_expr(df) + \\\n",
    "                Aggregator.other_expr(df) + \\\n",
    "                Aggregator.count_expr(df)\n",
    "\n",
    "        return exprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path, depth=None):\n",
    "    df = pl.read_parquet(path)\n",
    "    df = df.pipe(Pipeline.set_table_dtypes)\n",
    "    \n",
    "    if depth in [1, 2]:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def read_files(regex_path, depth=None):\n",
    "    chunks = []\n",
    "    for path in glob(str(regex_path)):\n",
    "        df = pl.read_parquet(path)\n",
    "        df = df.pipe(Pipeline.set_table_dtypes)\n",
    "        \n",
    "        if depth in [1, 2]:\n",
    "            df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "        \n",
    "        chunks.append(df)\n",
    "        \n",
    "    df = pl.concat(chunks, how=\"vertical_relaxed\")\n",
    "    df = df.unique(subset=[\"case_id\"])\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng(df_base, depth_0, depth_1, depth_2):\n",
    "    df_base = (\n",
    "        df_base\n",
    "        .with_columns(\n",
    "            month_decision = pl.col(\"date_decision\").dt.month(),\n",
    "            weekday_decision = pl.col(\"date_decision\").dt.weekday(),\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n",
    "        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n",
    "        \n",
    "    df_base = df_base.pipe(Pipeline.handle_dates)\n",
    "    \n",
    "    return df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pandas(df_data, cat_cols=None):\n",
    "    df_data = df_data.to_pandas()\n",
    "    \n",
    "    if cat_cols is None:\n",
    "        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n",
    "    \n",
    "    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n",
    "    \n",
    "    return df_data, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##ROOT            = Path(\"/kaggle/input/home-credit-credit-risk-model-stability\")\n",
    "##TRAIN_DIR       = ROOT / \"parquet_files\" / \"train\"\n",
    "##TEST_DIR        = ROOT / \"parquet_files\" / \"test\"\n",
    "\n",
    "from pathlib import Path\n",
    "TRAIN_DIR = Path(\"../parquet_files/train\")\n",
    "TEST_DIR = Path(\"../parquet_files/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store = {\n",
    "    \"df_base\": read_file(TRAIN_DIR / \"train_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        read_file(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n",
    "        read_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        read_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_other_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_person_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:\t (1526659, 472)\n"
     ]
    }
   ],
   "source": [
    "df_train = feature_eng(**data_store)\n",
    "\n",
    "print(\"train data shape:\\t\", df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store = {\n",
    "    \"df_base\": read_file(TEST_DIR / \"test_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        read_file(TEST_DIR / \"test_static_cb_0.parquet\"),\n",
    "        read_files(TEST_DIR / \"test_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        read_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n",
    "        read_files(TEST_DIR / \"test_credit_bureau_a_1_*.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_other_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_person_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_deposit_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        read_file(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n",
    "        read_files(TEST_DIR / \"test_credit_bureau_a_2_*.parquet\", 2),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data shape:\t (10, 471)\n"
     ]
    }
   ],
   "source": [
    "df_test = feature_eng(**data_store)\n",
    "\n",
    "print(\"test data shape:\\t\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['addres_district_368M', 'addres_role_871L', 'addres_zip_823M', 'amtinstpaidbefduel24m_4187115A', 'annualeffectiverate_199L', 'annuity_853A', 'applicationcnt_361L', 'applications30d_658L', 'applicationscnt_1086L', 'applicationscnt_464L', 'applicationscnt_629L', 'applicationscnt_867L', 'approvaldate_319D', 'assignmentdate_238D', 'assignmentdate_4527235D', 'assignmentdate_4955616D', 'bankacctype_710L', 'birth_259D', 'birthdate_574D', 'birthdate_87D', 'byoccupationinc_3656910L', 'cardtype_51L', 'childnum_21L', 'classificationofcontr_1114M', 'classificationofcontr_13M', 'classificationofcontr_400M', 'clientscnt_100L', 'clientscnt_1022L', 'clientscnt_1071L', 'clientscnt_1130L', 'clientscnt_136L', 'clientscnt_157L', 'clientscnt_257L', 'clientscnt_304L', 'clientscnt_360L', 'clientscnt_493L', 'clientscnt_533L', 'clientscnt_887L', 'clientscnt_946L', 'clientscnt12m_3712952L', 'clientscnt3m_3712950L', 'clientscnt6m_3712949L', 'cntpmts24_3658933L', 'collater_typofvalofguarant_298M', 'collater_typofvalofguarant_407M', 'collaterals_typeofguarante_359M', 'collaterals_typeofguarante_669M', 'contaddr_district_15M', 'contaddr_matchlist_1032L', 'contaddr_smempladdr_334L', 'contaddr_zipcode_807M', 'contractdate_551D', 'contractenddate_991D', 'contractmaturitydate_151D', 'contractst_964M', 'contractsum_5085717L', 'contracttype_653M', 'conts_role_79M', 'conts_type_509L', 'creationdate_885D', 'credlmt_228A', 'credlmt_230A', 'credor_3940957M', 'credtype_322L', 'credtype_587L', 'dateactivated_425D', 'datefirstoffer_1144D', 'datelastinstal40dpd_247D', 'datelastunpaid_3546854D', 'dateofcredend_289D', 'dateofcredend_353D', 'dateofcredstart_181D', 'dateofcredstart_739D', 'dateofrealrepmt_138D', 'deductiondate_4917603D', 'description_351M', 'description_5085714M', 'disbursementtype_67L', 'district_544M', 'dpdmaxdatemonth_804T', 'dpdmaxdatemonth_89T', 'dpdmaxdateyear_596T', 'dpdmaxdateyear_742T', 'dpdmaxdateyear_896T', 'dtlastpmt_581D', 'dtlastpmtallstes_3545839D', 'dtlastpmtallstes_4499206D', 'education_1103M', 'education_1138M', 'education_88M', 'education_927M', 'eir_270L', 'empl_employedfrom_271D', 'empladdr_district_926M', 'empladdr_zipcode_114M', 'employedfrom_700D', 'employername_160M', 'empls_employedfrom_796D', 'empls_employer_name_740M', 'familystate_447L', 'familystate_726L', 'financialinstitution_382M', 'financialinstitution_591M', 'firstclxcampaign_1125D', 'firstdatedue_489D', 'firstnonzeroinstldate_307D', 'fourthquarter_440L', 'gender_992L', 'housetype_905L', 'housingtype_772L', 'incometype_1044T', 'inittransactioncode_186L', 'inittransactioncode_279L', 'isbidproduct_1095L', 'isbidproduct_390L', 'isbidproductrequest_292L', 'isdebitcard_527L', 'isdebitcard_729L', 'language1_981M', 'last180dayturnover_1134A', 'last30dayturnover_651A', 'lastactivateddate_801D', 'lastapplicationdate_877D', 'lastapprcommoditycat_1041M', 'lastapprcommoditytypec_5251766M', 'lastapprdate_640D', 'lastcancelreason_561M', 'lastdelinqdate_224D', 'lastrejectcommoditycat_161M', 'lastrejectcommodtypec_5251769M', 'lastrejectdate_50D', 'lastrejectreason_759M', 'lastrejectreasonclient_4145040M', 'lastrepayingdate_696D', 'lastupdate_1112D', 'lastupdate_260D', 'lastupdate_388D', 'maritalst_385M', 'maritalst_703L', 'maritalst_893M', 'maxdpdinstldate_3546855D', 'mobilephncnt_593L', 'name_4527232M', 'name_4917606M', 'numberofoverdueinstlmaxdat_148D', 'numberofoverdueinstlmaxdat_641D', 'openingdate_313D', 'openingdate_857D', 'overdueamountmax2date_1002D', 'overdueamountmax2date_1142D', 'overdueamountmaxdatemonth_284T', 'overdueamountmaxdatemonth_365T', 'overdueamountmaxdatemonth_494T', 'overdueamountmaxdateyear_2T', 'overdueamountmaxdateyear_432T', 'overdueamountmaxdateyear_994T', 'paytype_783L', 'paytype1st_925L', 'payvacationpostpone_4187118D', 'periodicityofpmts_1102L', 'periodicityofpmts_837L', 'personindex_1023L', 'persontype_1072L', 'persontype_792L', 'posfpd10lastmonth_333P', 'posfpd30lastmonth_3976960P', 'posfstqpd30lastmonth_3976962P', 'postype_4733339M', 'previouscontdistrict_112M', 'processingdate_168D', 'purposeofcred_426M', 'purposeofcred_722M', 'purposeofcred_874M', 'registaddr_district_1083M', 'registaddr_zipcode_184M', 'rejectreason_755M', 'rejectreasonclient_4145042M', 'relatedpersons_role_762T', 'relationshiptoclient_415T', 'relationshiptoclient_642T', 'requesttype_4525192L', 'responsedate_1012D', 'responsedate_4527233D', 'responsedate_4917613D', 'role_1084L', 'role_993L', 'secondquarter_766L', 'sellerplacecnt_915L', 'sellerplacescnt_216L', 'sex_738L', 'subjectrole_182M', 'subjectrole_326M', 'subjectrole_43M', 'subjectrole_93M', 'thirdquarter_1082L', 'twobodfilling_608L', 'type_25L', 'typesuite_864L', 'validfrom_1069D'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert train data to pandas and filter\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df_train, cat_cols \u001b[38;5;241m=\u001b[39m to_pandas(df_train)\n\u001b[1;32m----> 3\u001b[0m df_train_filtered \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Convert test data to pandas and filter\u001b[39;00m\n\u001b[0;32m      6\u001b[0m df_test, cat_cols \u001b[38;5;241m=\u001b[39m to_pandas(df_test, cat_cols)\n",
      "File \u001b[1;32mc:\\Users\\NITRO 5\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:6228\u001b[0m, in \u001b[0;36mNDFrame.pipe\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   6226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m   6227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m common\u001b[38;5;241m.\u001b[39mpipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 6228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcommon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\NITRO 5\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\common.py:502\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m(obj, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[81], line 95\u001b[0m, in \u001b[0;36mPipeline.filter_cols\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     35\u001b[0m excluded_attributes \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddres_district_368M\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddres_role_871L\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddres_zip_823M\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamtinstpaidbefduel24m_4187115A\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannualeffectiverate_199L\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannuity_853A\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthirdquarter_1082L\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwobodfilling_608L\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype_25L\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtypesuite_864L\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidfrom_1069D\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m ]\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Exclude the attributes\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexcluded_attributes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m    \u001b[38;5;66;03m# Print the number of columns left\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of columns left after excluding:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns))\n",
      "File \u001b[1;32mc:\\Users\\NITRO 5\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5568\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5422\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5429\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5431\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5432\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5433\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5566\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5567\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5570\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5574\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5575\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5576\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\NITRO 5\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4785\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4783\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4785\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\NITRO 5\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4827\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4825\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4827\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4828\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4830\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\NITRO 5\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['addres_district_368M', 'addres_role_871L', 'addres_zip_823M', 'amtinstpaidbefduel24m_4187115A', 'annualeffectiverate_199L', 'annuity_853A', 'applicationcnt_361L', 'applications30d_658L', 'applicationscnt_1086L', 'applicationscnt_464L', 'applicationscnt_629L', 'applicationscnt_867L', 'approvaldate_319D', 'assignmentdate_238D', 'assignmentdate_4527235D', 'assignmentdate_4955616D', 'bankacctype_710L', 'birth_259D', 'birthdate_574D', 'birthdate_87D', 'byoccupationinc_3656910L', 'cardtype_51L', 'childnum_21L', 'classificationofcontr_1114M', 'classificationofcontr_13M', 'classificationofcontr_400M', 'clientscnt_100L', 'clientscnt_1022L', 'clientscnt_1071L', 'clientscnt_1130L', 'clientscnt_136L', 'clientscnt_157L', 'clientscnt_257L', 'clientscnt_304L', 'clientscnt_360L', 'clientscnt_493L', 'clientscnt_533L', 'clientscnt_887L', 'clientscnt_946L', 'clientscnt12m_3712952L', 'clientscnt3m_3712950L', 'clientscnt6m_3712949L', 'cntpmts24_3658933L', 'collater_typofvalofguarant_298M', 'collater_typofvalofguarant_407M', 'collaterals_typeofguarante_359M', 'collaterals_typeofguarante_669M', 'contaddr_district_15M', 'contaddr_matchlist_1032L', 'contaddr_smempladdr_334L', 'contaddr_zipcode_807M', 'contractdate_551D', 'contractenddate_991D', 'contractmaturitydate_151D', 'contractst_964M', 'contractsum_5085717L', 'contracttype_653M', 'conts_role_79M', 'conts_type_509L', 'creationdate_885D', 'credlmt_228A', 'credlmt_230A', 'credor_3940957M', 'credtype_322L', 'credtype_587L', 'dateactivated_425D', 'datefirstoffer_1144D', 'datelastinstal40dpd_247D', 'datelastunpaid_3546854D', 'dateofcredend_289D', 'dateofcredend_353D', 'dateofcredstart_181D', 'dateofcredstart_739D', 'dateofrealrepmt_138D', 'deductiondate_4917603D', 'description_351M', 'description_5085714M', 'disbursementtype_67L', 'district_544M', 'dpdmaxdatemonth_804T', 'dpdmaxdatemonth_89T', 'dpdmaxdateyear_596T', 'dpdmaxdateyear_742T', 'dpdmaxdateyear_896T', 'dtlastpmt_581D', 'dtlastpmtallstes_3545839D', 'dtlastpmtallstes_4499206D', 'education_1103M', 'education_1138M', 'education_88M', 'education_927M', 'eir_270L', 'empl_employedfrom_271D', 'empladdr_district_926M', 'empladdr_zipcode_114M', 'employedfrom_700D', 'employername_160M', 'empls_employedfrom_796D', 'empls_employer_name_740M', 'familystate_447L', 'familystate_726L', 'financialinstitution_382M', 'financialinstitution_591M', 'firstclxcampaign_1125D', 'firstdatedue_489D', 'firstnonzeroinstldate_307D', 'fourthquarter_440L', 'gender_992L', 'housetype_905L', 'housingtype_772L', 'incometype_1044T', 'inittransactioncode_186L', 'inittransactioncode_279L', 'isbidproduct_1095L', 'isbidproduct_390L', 'isbidproductrequest_292L', 'isdebitcard_527L', 'isdebitcard_729L', 'language1_981M', 'last180dayturnover_1134A', 'last30dayturnover_651A', 'lastactivateddate_801D', 'lastapplicationdate_877D', 'lastapprcommoditycat_1041M', 'lastapprcommoditytypec_5251766M', 'lastapprdate_640D', 'lastcancelreason_561M', 'lastdelinqdate_224D', 'lastrejectcommoditycat_161M', 'lastrejectcommodtypec_5251769M', 'lastrejectdate_50D', 'lastrejectreason_759M', 'lastrejectreasonclient_4145040M', 'lastrepayingdate_696D', 'lastupdate_1112D', 'lastupdate_260D', 'lastupdate_388D', 'maritalst_385M', 'maritalst_703L', 'maritalst_893M', 'maxdpdinstldate_3546855D', 'mobilephncnt_593L', 'name_4527232M', 'name_4917606M', 'numberofoverdueinstlmaxdat_148D', 'numberofoverdueinstlmaxdat_641D', 'openingdate_313D', 'openingdate_857D', 'overdueamountmax2date_1002D', 'overdueamountmax2date_1142D', 'overdueamountmaxdatemonth_284T', 'overdueamountmaxdatemonth_365T', 'overdueamountmaxdatemonth_494T', 'overdueamountmaxdateyear_2T', 'overdueamountmaxdateyear_432T', 'overdueamountmaxdateyear_994T', 'paytype_783L', 'paytype1st_925L', 'payvacationpostpone_4187118D', 'periodicityofpmts_1102L', 'periodicityofpmts_837L', 'personindex_1023L', 'persontype_1072L', 'persontype_792L', 'posfpd10lastmonth_333P', 'posfpd30lastmonth_3976960P', 'posfstqpd30lastmonth_3976962P', 'postype_4733339M', 'previouscontdistrict_112M', 'processingdate_168D', 'purposeofcred_426M', 'purposeofcred_722M', 'purposeofcred_874M', 'registaddr_district_1083M', 'registaddr_zipcode_184M', 'rejectreason_755M', 'rejectreasonclient_4145042M', 'relatedpersons_role_762T', 'relationshiptoclient_415T', 'relationshiptoclient_642T', 'requesttype_4525192L', 'responsedate_1012D', 'responsedate_4527233D', 'responsedate_4917613D', 'role_1084L', 'role_993L', 'secondquarter_766L', 'sellerplacecnt_915L', 'sellerplacescnt_216L', 'sex_738L', 'subjectrole_182M', 'subjectrole_326M', 'subjectrole_43M', 'subjectrole_93M', 'thirdquarter_1082L', 'twobodfilling_608L', 'type_25L', 'typesuite_864L', 'validfrom_1069D'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Convert train data to pandas and filter\n",
    "df_train, cat_cols = to_pandas(df_train)\n",
    "df_train_filtered = df_train.pipe(Pipeline.filter_cols)\n",
    "\n",
    "# Convert test data to pandas and filter\n",
    "df_test, cat_cols = to_pandas(df_test, cat_cols)\n",
    "df_test_filtered = df_test.pipe(Pipeline.filter_cols)\n",
    "\n",
    "# Ensure that both train and test data have the same columns except for the target attribute\n",
    "common_columns = list(set(df_train_filtered.columns).intersection(set(df_test_filtered.columns)))\n",
    "\n",
    "# Add specific columns to the common columns list if they are not already present\n",
    "columns_to_keep = ['case_id', 'WEEK_NUM', 'month_decision', 'weekday_decision']\n",
    "for col in columns_to_keep:\n",
    "    if col not in common_columns:\n",
    "        common_columns.append(col)\n",
    "\n",
    "# Preserve the original order of columns in df_train_filtered\n",
    "common_columns = [col for col in df_train_filtered.columns if col in common_columns]\n",
    "\n",
    "# Add 'target' column to train data\n",
    "df_train_filtered = df_train_filtered[common_columns + ['target']]\n",
    "\n",
    "# Filter test data to include only common columns\n",
    "df_test_filtered = df_test_filtered[common_columns]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train, cat_cols = to_pandas(df_train)\n",
    "# df_test, cat_cols = to_pandas(df_test, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del data_store\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train is duplicated:\\t\", df_train_filtered[\"case_id\"].duplicated().any())\n",
    "print(\"Train Week Range:\\t\", (df_train_filtered[\"WEEK_NUM\"].min(), df_train[\"WEEK_NUM\"].max()))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Test is duplicated:\\t\", df_test_filtered[\"case_id\"].duplicated().any())\n",
    "print(\"Test Week Range:\\t\", (df_test_filtered[\"WEEK_NUM\"].min(), df_test[\"WEEK_NUM\"].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(\n",
    "#     data=df_train,\n",
    "#     x=\"WEEK_NUM\",\n",
    "#     y=\"target\",\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_filtered.drop(columns=[\"target\", \"case_id\", \"WEEK_NUM\"])\n",
    "y = df_train_filtered[\"target\"]\n",
    "weeks = df_train_filtered[\"WEEK_NUM\"]\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"max_depth\": 8,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"colsample_bytree\": 0.8, \n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"verbose\": -1,\n",
    "    \"random_state\": 42,\n",
    "    \"class_weight\": \"balanced\",\n",
    "    #\"device\": \"gpu\",\n",
    "}\n",
    "\n",
    "fitted_models = []\n",
    "\n",
    "for idx_train, idx_valid in cv.split(X, y, groups=weeks):\n",
    "    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        callbacks=[lgb.log_evaluation(100), lgb.early_stopping(100)]\n",
    "    )\n",
    "\n",
    "    fitted_models.append(model)\n",
    "\n",
    "model = VotingModel(fitted_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test_filtered.drop(columns=[\"WEEK_NUM\"])\n",
    "X_test = X_test.set_index(\"case_id\")\n",
    "\n",
    "y_pred = pd.Series(model.predict_proba(X_test)[:, 1], index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subm = pd.read_csv(\"sample_submission.csv\")\n",
    "df_subm = df_subm.set_index(\"case_id\")\n",
    "\n",
    "df_subm[\"score\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check null: \", df_subm[\"score\"].isnull().any())\n",
    "\n",
    "df_subm_sorted = df_subm.sort_values(by=\"score\", ascending=False)\n",
    "top_5_scores = df_subm_sorted.head()\n",
    "print(top_5_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subm.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
